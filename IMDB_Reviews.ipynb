{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_Reviews.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOpBbrdUnVe0DVpoB1rpTyi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meriembenchaaben/NLP_with_tensorflow/blob/master/IMDB_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXJR9y_hTf1g",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing , In the beginnig we have some codes to test the diffrent preprocessing tasks and then we have the real work on the reviews of IMDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-K2s53TGOT2",
        "colab_type": "code",
        "outputId": "077aa640-07c1-4459-8af6-de5ea8ab16cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import csv\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J86B3HCWXeCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from scipy.stats import chi2_contingency, ttest_ind, ttest_rel, f_oneway\n",
        "%matplotlib inline\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import seaborn as sns\n",
        "rc('pdf', fonttype=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yePw57cOTXUX",
        "colab_type": "text"
      },
      "source": [
        "Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf4HVCT9TKiH",
        "colab_type": "code",
        "outputId": "cf3f27fe-3840-4810-a9af-66ecebc60ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(len(word_index))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUtMcuDuTVqf",
        "colab_type": "text"
      },
      "source": [
        "Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG3rPP_YTlco",
        "colab_type": "text"
      },
      "source": [
        "Labels :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvVZ9iGPTcd_",
        "colab_type": "code",
        "outputId": "64a2b1da-8ed3-4dec-c1f3-b567dfcc92a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "label_tokenizer = Tokenizer()\n",
        "label_tokenizer.fit_on_texts(labels)\n",
        "label_word_index = label_tokenizer.word_index\n",
        "label_seq = label_tokenizer.texts_to_sequences(labels)\n",
        "print(label_seq)\n",
        "print(label_word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "{}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVjj6IsxU0qH",
        "colab_type": "text"
      },
      "source": [
        "IMDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro_jkPhHYWws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpf0TbI0NTpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_data, test_data = imdb['train'], imdb['test']\n",
        "\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []\n",
        "\n",
        "for s,l in train_data:\n",
        "  training_sentences.append(str(s.numpy()))\n",
        "  training_labels.append(l.numpy())\n",
        "  \n",
        "for s,l in test_data:\n",
        "  testing_sentences.append(str(s.numpy()))\n",
        "  testing_labels.append(l.numpy())\n",
        "  \n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Va31XuwN1A4",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hDRncqzNnLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqkpm-CYN7SG",
        "colab_type": "code",
        "outputId": "2d62c0b2-d45f-4c02-dcfc-39f59e0078fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "print(decode_review(padded[1]))\n",
        "print(training_sentences[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "? ? ? ? ? ? ? b'i have been known to fall asleep during films but this is usually due to a combination of things including really tired being warm and comfortable on the <OOV> and having just eaten a lot however on this occasion i fell asleep because the film was rubbish the plot development was constant constantly slow and boring things seemed to happen but with no explanation of what was causing them or why i admit i may have missed part of the film but i watched the majority of it and everything just seemed to happen of its own <OOV> without any real concern for anything else i cant recommend this film at all '\n",
            "b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBdQbc20OsBx",
        "colab_type": "text"
      },
      "source": [
        "summary to describe the model and it's layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMs7BMhTPjmu",
        "colab_type": "text"
      },
      "source": [
        "here we have bianry_crossentropy as loss function + sigmoid in the final layer since it's clasification model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF00LQA1OdZx",
        "colab_type": "code",
        "outputId": "36b13f74-bfb0-4817-9cb9-398846ea31ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 120, 16)           160000    \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 6)                 11526     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 171,533\n",
            "Trainable params: 171,533\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smhYv9oePYL7",
        "colab_type": "code",
        "outputId": "094fd150-351d-4ea2-cbe2-b0540b1a08f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "num_epochs = 10\n",
        "model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))\n",
        "#Accuracy 1 !!!!? Most likely overfit"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.4989 - accuracy: 0.7358 - val_loss: 0.3446 - val_accuracy: 0.8480\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2384 - accuracy: 0.9071 - val_loss: 0.3706 - val_accuracy: 0.8383\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0895 - accuracy: 0.9772 - val_loss: 0.4562 - val_accuracy: 0.8260\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0216 - accuracy: 0.9973 - val_loss: 0.5252 - val_accuracy: 0.8264\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0051 - accuracy: 0.9999 - val_loss: 0.5824 - val_accuracy: 0.8281\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6357 - val_accuracy: 0.8288\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 8.8346e-04 - accuracy: 1.0000 - val_loss: 0.6760 - val_accuracy: 0.8288\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 4.5571e-04 - accuracy: 1.0000 - val_loss: 0.7143 - val_accuracy: 0.8290\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.6814e-04 - accuracy: 1.0000 - val_loss: 0.7526 - val_accuracy: 0.8295\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.6240e-04 - accuracy: 1.0000 - val_loss: 0.7880 - val_accuracy: 0.8288\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcbc30bc7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3wA9mdcUJAp",
        "colab_type": "text"
      },
      "source": [
        "Get the results of the embedding layes , layers[0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNVku404PbMg",
        "colab_type": "code",
        "outputId": "20fe4861-e301-4029-b02d-c8e1b888f8ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)\n",
        "#the result is 10000 as our nuber of words in the corpus !"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP3JPuBKQtLY",
        "colab_type": "text"
      },
      "source": [
        "this code creates the files containig the words and their vectors (results of embedding) so that it can be use in other work !\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEStQIAKP9o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWntPf3OSglV",
        "colab_type": "text"
      },
      "source": [
        "each line corresponds to  word in vecs.tsv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpbVEZ5wQI3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dwnload it !\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MPtWPp3Vro-",
        "colab_type": "text"
      },
      "source": [
        "It's cool to use Embedding Projector \n",
        "https://projector.tensorflow.org/"
      ]
    }
  ]
}